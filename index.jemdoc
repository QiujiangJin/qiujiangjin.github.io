# jemdoc: menu{MENU}{index.html}, nofooter  
==Qiujiang Jin

~~~
{}{img_left}{image.jpg}{alt text}{200}{200}
Graduated Ph.D. student\n [https://www.ece.utexas.edu/ Department of Electrical and Computer Engineering]\n [https://wncg.org/ Wireless Networking and Communications Group]\n [https://www.utexas.edu/ University of Texas at Austin]\n
E-mail: qiujiangjin0@gmail.com
~~~

== About me
I graduated with my Ph.D. degree from the [https://www.ece.utexas.edu/ Department of Electrical and Computer Engineering] of [https://www.utexas.edu/ University of Texas at Austin]. I was a member of the [https://wncg.org/ Wireless Networking and Communications Group] and I was advised by [https://sites.utexas.edu/mokhtari/ Prof. Aryan Mokhtari]. I received my B.Sc. in pure and applied mathematics  from the [https://www.math.tsinghua.edu.cn/ Department of Mathematical Sciences] at [https://www.tsinghua.edu.cn/en/ Tsinghua University] and my M.Sc. in computational and mathematical engineering from the [https://icme.stanford.edu/ Institute for Computational & Mathematical Engineering] at [https://www.stanford.edu/ Stanford University]. My research interests generally lie in the theory and applications of optimization. My current research focuses on the development of efficient second-order numerical optimization methods for large-scale machine learning problems.

=== PhD Thesis
\[[https://repositories.lib.utexas.edu/server/api/core/bitstreams/588d783b-4a51-4066-9e88-c776b91fba6f/content Non-asymptotic Study of Quasi-Newton Methods with Application in Large-scale Machine Learning]\]

=== Publications and Preprints
. \[[https://arxiv.org/abs/2003.13607 Non-asymptotic Superlinear Convergence of Standard Quasi-Newton Methods]\]\n Qiujiang Jin and Aryan Mokhtari\n Mathematical Programming, 1-49, 2022.
. \[[https://arxiv.org/abs/2106.05445 Exploiting Local Convergence of Quasi-Newton Methods Globally: Adaptive Sample Size Approach]\]\n Qiujiang Jin and Aryan Mokhtari\n Advances in Neural Information Processing Systems (NeurIPS), 2021.
. \[[https://arxiv.org/abs/2202.10538 Sharpened Quasi-Newton Methods: Faster Superlinear Rate and Larger Local Convergence Neighborhood]\]\n Qiujiang Jin, Alec Koppel, Ketan Rajawat and Aryan Mokhtari\n International Conference on Machine Learning (ICML), 2022.
. \[[https://arxiv.org/abs/2302.08580 Online Learning Guided Curvature Approximation: A Quasi-Newton Method with Global Non-Asymptotic Superlinear Convergence]\]\n Ruichen Jiang, Qiujiang Jin and Aryan Mokhtari\n Conference on Learning Theory (COLT), 2023.
. \[[https://arxiv.org/abs/2206.00207 Statistical and Computational Complexities of BFGS Quasi-Newton Method for Generalized Linear Models]\]\n Qiujiang Jin, Tongzheng Ren, Nhat Ho and Aryan Mokhtari\n Transactions on Machine Learning Research, 2024.
. \[[https://arxiv.org/abs/2404.16731 Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search]\]\n Qiujiang Jin, Ruichen Jiang and Aryan Mokhtari\n Advances in Neural Information Processing Systems (NeurIPS), 2024. *(Spotlight)*
. \[[https://arxiv.org/abs/2406.02016 Adaptive and Optimal Second-order Optimistic Methods for Minimax Optimization]\]\n Ruichen Jiang, Ali Kavis, Qiujiang Jin, Sujay Sanghavi and Aryan Mokhtari\n Advances in Neural Information Processing Systems (NeurIPS), 2024.
. \[[https://arxiv.org/abs/2404.01267 Non-asymptotic Global Convergence Rates of BFGS with Exact Line Search]\]\n Qiujiang Jin, Ruichen Jiang and Aryan Mokhtari\n Mathematical Programming, 2025.
. \[[https://arxiv.org/abs/2507.00361 Affine-Invariant Global Non-Asymptotic Convergence Analysis of BFGS under Self-Concordance]\]\n Qiujiang Jin and Aryan Mokhtari\n Advances in Neural Information Processing Systems (NeurIPS), 2025. *(Spotlight)*
